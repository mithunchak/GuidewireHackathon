{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11138703,"sourceType":"datasetVersion","datasetId":6947811}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\n\n# Load dataset\ndef load_data(file_path):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"File {file_path} not found\")\n    df = pd.read_csv(file_path)\n    print(\"Columns:\", df.columns.tolist())\n    time_cols = ['Pod Event Age', 'Event Age']\n    for col in time_cols:\n        if col in df.columns:\n            df[col] = df[col].apply(lambda x: sum(int(t) * 60 ** i for i, t in enumerate(reversed(str(x).split(':')))))\n    return df\n\n# Feature and target columns\ndef get_feature_target_columns(df):\n    target_columns = [\n        'Pod_Status_Failure', 'Pod_Event_Failure', 'Pod_Event_Reason_Failure',\n        'Resource_Failure', 'Pod_Restart_Failure', 'Network_Failure', 'Disk_Failure'\n    ]\n    available_targets = [col for col in target_columns if col in df.columns]\n    if not available_targets:\n        raise ValueError(\"No target columns found!\")\n    non_feature_columns = available_targets + [col for col in df.columns if df[col].dtype == 'object']\n    feature_columns = [col for col in df.columns if col not in non_feature_columns]\n    return feature_columns, available_targets\n\n# Create a single target (any failure = 1, no failure = 0)\ndef create_combined_target(df, target_columns):\n    df['Any_Failure'] = df[target_columns].max(axis=1)  # 1 if any failure type is 1, else 0\n    return df\n\n# Forecast features using moving averages\ndef forecast_features(pod_data, feature_columns, forecast_periods=1):\n    forecasted_features = {}\n    for feature in feature_columns:\n        values = pod_data[feature].values\n        if len(values) < 3:\n            forecasted_features[feature] = values[-1]\n        else:\n            window_size = min(5, len(values))\n            forecasted_features[feature] = np.mean(values[-window_size:])\n    return forecasted_features\n\n# Build and train a Keras single-output model\ndef build_and_train_model(X_train, y_train, epochs=50, batch_size=32):\n    input_dim = X_train.shape[1]\n\n    # Define the model\n    inputs = Input(shape=(input_dim,))\n    x = Dense(128, activation='relu')(inputs)\n    x = Dropout(0.3)(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    output = Dense(1, activation='sigmoid', name='output')(x)  # Single output\n    \n    # Create and compile the model\n    model = Model(inputs=inputs, outputs=output)\n    model.compile(optimizer='adam', \n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    # Early stopping\n    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    \n    # Train the model\n    history = model.fit(X_train, y_train, \n                        epochs=epochs, \n                        batch_size=batch_size, \n                        validation_split=0.2, \n                        callbacks=[early_stopping], \n                        verbose=1)\n    \n    return model, history\n\n# Predict failures and save model\ndef predict_pod_failures(pod_data, feature_columns, target_columns, forecast_time_steps=1):\n    print(\"Preparing data...\")\n    pod_data = create_combined_target(pod_data, target_columns)  # Add combined target\n    scaler = StandardScaler()\n    X = scaler.fit_transform(pod_data[feature_columns])\n    X = pd.DataFrame(X, columns=feature_columns)\n    y = pod_data['Any_Failure']\n    \n    print(\"Splitting data...\")\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n    \n    print(\"Training Keras model...\")\n    model, history = build_and_train_model(X_train, y_train)\n    \n    # Save the model and scaler\n    model.save(\"model.h5\")\n    with open(\"scaler.pkl\", \"wb\") as f:\n        pickle.dump(scaler, f)\n    print(\"Model saved as 'model.h5' and scaler saved as 'scaler.pkl'\")\n    \n    # Evaluate on test data\n    evaluation = model.evaluate(X_test, y_test, verbose=0)\n    evaluation_results = {'val_loss': evaluation[0], 'val_acc': evaluation[1]}\n    \n    # Forecast for a sample of pods\n    sample_pods = pod_data['Pod Name'].unique()[:min(20, len(pod_data['Pod Name'].unique()))]\n    future_predictions = {}\n    \n    print(\"Forecasting future failures...\")\n    for pod_name in sample_pods:\n        pod_df = pod_data[pod_data['Pod Name'] == pod_name].copy()\n        forecasted_features = forecast_features(pod_df, feature_columns)\n        future_features = pd.DataFrame([forecasted_features])\n        future_features_scaled = scaler.transform(future_features)\n        \n        # Predict with the model\n        prediction = model.predict(future_features_scaled, verbose=0)[0][0]\n        future_predictions[pod_name] = {'Any_Failure': int(prediction > 0.5)}\n    \n    return evaluation_results, future_predictions, scaler, history\n\n# Plot feature trends\ndef plot_feature_trends(pod_data, pod_name, feature_columns, max_features=3):\n    pod_df = pod_data[pod_data['Pod Name'] == pod_name].copy()\n    if pod_df.empty:\n        print(f\"No data found for pod {pod_name}\")\n        return None\n    \n    features_to_plot = feature_columns[:min(max_features, len(feature_columns))]\n    fig, axs = plt.subplots(len(features_to_plot), 1, figsize=(10, 3*len(features_to_plot)))\n    if len(features_to_plot) == 1:\n        axs = [axs]\n    \n    for i, feature in enumerate(features_to_plot):\n        values = pod_df[feature].values\n        axs[i].plot(range(len(values)), values, 'b-', label='Historical')\n        axs[i].set_title(f'{feature} for {pod_name}')\n        axs[i].legend()\n    \n    plt.tight_layout()\n    plt.savefig(f\"trends_{pod_name}.png\")\n    plt.close()\n    print(f\"Saved plot to trends_{pod_name}.png\")\n\n# Plot training history\ndef plot_training_history(history):\n    plt.figure(figsize=(10, 5))\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss During Training')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('training_history_loss.png')\n    plt.close()\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy During Training')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('training_history_accuracy.png')\n    plt.close()\n    print(\"Saved training history plots\")\n\n# Main function\ndef main(file_path):\n    print(\"Starting execution...\")\n    pod_data = load_data(file_path)\n    feature_columns, target_columns = get_feature_target_columns(pod_data)\n    print(f\"Dataset: {len(pod_data)} rows, {len(feature_columns)} features, {len(target_columns)} targets\")\n    \n    evaluation_results, future_predictions, scaler, history = predict_pod_failures(\n        pod_data, feature_columns, target_columns\n    )\n    \n    print(\"\\nModel Evaluation Results:\")\n    print(f\"Validation Loss: {evaluation_results['val_loss']:.4f}\")\n    print(f\"Validation Accuracy: {evaluation_results['val_acc']:.4f}\")\n    \n    print(\"\\nFuture Predictions:\")\n    for pod_name, predictions in future_predictions.items():\n        print(f\"\\n{pod_name}:\")\n        print(f\"  Any_Failure: {'Failure' if predictions['Any_Failure'] == 1 else 'No Failure'}\")\n    \n    sample_pod = pod_data['Pod Name'].iloc[0]\n    plot_feature_trends(pod_data, sample_pod, feature_columns)\n    plot_training_history(history)\n\nif __name__ == \"__main__\":\n    file_path = \"/kaggle/input/fulldata/Transformed_Dataset/transformed_dataset.csv\"  # Update this\n    main(file_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T16:43:01.133827Z","iopub.execute_input":"2025-03-23T16:43:01.134077Z","iopub.status.idle":"2025-03-23T16:46:13.418982Z","shell.execute_reply.started":"2025-03-23T16:43:01.134056Z","shell.execute_reply":"2025-03-23T16:46:13.418092Z"}},"outputs":[{"name":"stdout","text":"Starting execution...\nColumns: ['Pod Status', 'Pod Event Type', 'Pod Event Reason', 'CPU Usage (%)', 'Memory Usage (%)', 'Pod Restarts', 'Network Receive Packets Dropped (p/s)', 'Network Transmit Packets Dropped (p/s)', 'FS Reads Total (MB)', 'FS Writes Total (MB)', 'Pod Name', 'Node Name', 'Ready Containers', 'Total Containers', 'Pod Event Age', 'Pod Event Source', 'Event Age', 'Event Source', 'Hour', 'Day', 'Month', 'Weekday', 'Pod_Status_Failure', 'Pod_Event_Failure', 'Pod_Event_Reason_Failure', 'Resource_Failure', 'Pod_Restart_Failure', 'Network_Failure', 'Disk_Failure']\nDataset: 100000 rows, 20 features, 7 targets\nPreparing data...\nSplitting data...\nTraining Keras model...\nEpoch 1/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 7.1250e-07\nEpoch 2/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7331e-06 - val_accuracy: 1.0000 - val_loss: 6.0306e-08\nEpoch 3/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0612e-06 - val_accuracy: 1.0000 - val_loss: 8.3652e-09\nEpoch 4/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1399e-07 - val_accuracy: 1.0000 - val_loss: 1.3973e-09\nEpoch 5/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3606e-08 - val_accuracy: 1.0000 - val_loss: 2.4922e-10\nEpoch 6/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5909e-08 - val_accuracy: 1.0000 - val_loss: 5.4938e-11\nEpoch 7/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2191e-08 - val_accuracy: 1.0000 - val_loss: 6.0805e-12\nEpoch 8/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8557e-09 - val_accuracy: 1.0000 - val_loss: 1.9702e-12\nEpoch 9/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1039e-09 - val_accuracy: 1.0000 - val_loss: 5.2128e-13\nEpoch 10/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6989e-10 - val_accuracy: 1.0000 - val_loss: 2.1141e-13\nEpoch 11/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4502e-10 - val_accuracy: 1.0000 - val_loss: 1.1146e-13\nEpoch 12/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0708e-10 - val_accuracy: 1.0000 - val_loss: 3.8543e-14\nEpoch 13/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7892e-10 - val_accuracy: 1.0000 - val_loss: 2.4475e-14\nEpoch 14/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0926e-11 - val_accuracy: 1.0000 - val_loss: 1.8210e-14\nEpoch 15/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4751e-10 - val_accuracy: 1.0000 - val_loss: 1.1633e-14\nEpoch 16/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1105e-11 - val_accuracy: 1.0000 - val_loss: 8.9910e-15\nEpoch 17/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8426e-11 - val_accuracy: 1.0000 - val_loss: 7.4451e-15\nEpoch 18/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5439e-11 - val_accuracy: 1.0000 - val_loss: 6.8841e-15\nEpoch 19/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7114e-11 - val_accuracy: 1.0000 - val_loss: 6.2424e-15\nEpoch 20/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1897e-11 - val_accuracy: 1.0000 - val_loss: 5.6353e-15\nEpoch 21/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4329e-11 - val_accuracy: 1.0000 - val_loss: 5.1141e-15\nEpoch 22/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4369e-11 - val_accuracy: 1.0000 - val_loss: 4.7151e-15\nEpoch 23/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4832e-11 - val_accuracy: 1.0000 - val_loss: 4.3001e-15\nEpoch 24/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5368e-11 - val_accuracy: 1.0000 - val_loss: 4.0527e-15\nEpoch 25/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.8790e-12 - val_accuracy: 1.0000 - val_loss: 3.8686e-15\nEpoch 26/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8982e-11 - val_accuracy: 1.0000 - val_loss: 3.6525e-15\nEpoch 27/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1236e-11 - val_accuracy: 1.0000 - val_loss: 2.6966e-15\nEpoch 28/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7997e-11 - val_accuracy: 1.0000 - val_loss: 2.3106e-15\nEpoch 29/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0000e-11 - val_accuracy: 1.0000 - val_loss: 2.2030e-15\nEpoch 30/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0681e-11 - val_accuracy: 1.0000 - val_loss: 2.0165e-15\nEpoch 31/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4342e-11 - val_accuracy: 1.0000 - val_loss: 1.8063e-15\nEpoch 32/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0842e-12 - val_accuracy: 1.0000 - val_loss: 1.7529e-15\nEpoch 33/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6459e-12 - val_accuracy: 1.0000 - val_loss: 1.7098e-15\nEpoch 34/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3896e-11 - val_accuracy: 1.0000 - val_loss: 1.6390e-15\nEpoch 35/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9950e-11 - val_accuracy: 1.0000 - val_loss: 1.5500e-15\nEpoch 36/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1375e-12 - val_accuracy: 1.0000 - val_loss: 1.5116e-15\nEpoch 37/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0749e-12 - val_accuracy: 1.0000 - val_loss: 1.4712e-15\nEpoch 38/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5092e-12 - val_accuracy: 1.0000 - val_loss: 1.4278e-15\nEpoch 39/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0120e-12 - val_accuracy: 1.0000 - val_loss: 1.3808e-15\nEpoch 40/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.2598e-12 - val_accuracy: 1.0000 - val_loss: 1.3431e-15\nEpoch 41/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6566e-12 - val_accuracy: 1.0000 - val_loss: 1.3093e-15\nEpoch 42/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5291e-11 - val_accuracy: 1.0000 - val_loss: 1.2464e-15\nEpoch 43/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8816e-12 - val_accuracy: 1.0000 - val_loss: 1.2113e-15\nEpoch 44/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9658e-12 - val_accuracy: 1.0000 - val_loss: 1.1836e-15\nEpoch 45/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5906e-12 - val_accuracy: 1.0000 - val_loss: 1.1300e-15\nEpoch 46/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1202e-12 - val_accuracy: 1.0000 - val_loss: 1.1082e-15\nEpoch 47/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.4679e-11 - val_accuracy: 1.0000 - val_loss: 8.0712e-16\nEpoch 48/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1810e-12 - val_accuracy: 1.0000 - val_loss: 7.8511e-16\nEpoch 49/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2083e-12 - val_accuracy: 1.0000 - val_loss: 7.7119e-16\nEpoch 50/50\n\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8100e-12 - val_accuracy: 1.0000 - val_loss: 7.4230e-16\nModel saved as 'model.h5' and scaler saved as 'scaler.pkl'\nForecasting future failures...\n\nModel Evaluation Results:\nValidation Loss: 0.0000\nValidation Accuracy: 1.0000\n\nFuture Predictions:\n\nopentelemetry-demo-currencyservice-77f76b5c58-2xk6g:\n  Any_Failure: Failure\n\nopentelemetry-demo-shippingservice-86ccddbd5b-6w8z7:\n  Any_Failure: Failure\n\nopentelemetry-demo-frontendproxy-588c77dd7c-w78jm:\n  Any_Failure: Failure\n\nopentelemetry-demo-ffspostgres-7464b97d47-vjbrm:\n  Any_Failure: Failure\n\nopentelemetry-demo-emailservice-dd9b599db-hctwt:\n  Any_Failure: Failure\n\nopentelemetry-demo-frontend-76f486559f-qz9ft:\n  Any_Failure: Failure\n\nopentelemetry-demo-frontend-76f486559f-zfwsj:\n  Any_Failure: Failure\n\nopentelemetry-demo-checkoutservice-7d546c4b8-bh4mp:\n  Any_Failure: Failure\n\nopentelemetry-demo-paymentservice-5fcfd5559c-skr74:\n  Any_Failure: Failure\n\nopentelemetry-demo-quoteservice-6fd674f94f-j85d8:\n  Any_Failure: Failure\n\nopentelemetry-demo-recommendationservice-7697d65f77-j75rv:\n  Any_Failure: Failure\n\nopentelemetry-demo-productcatalogservice-84f77b664d-bswjj:\n  Any_Failure: Failure\n\nopentelemetry-demo-recommendationservice-7697d65f77-xnkmr:\n  Any_Failure: Failure\n\nopentelemetry-demo-cartservice-56c6b98587-tsfjc:\n  Any_Failure: Failure\n\nopentelemetry-demo-shippingservice-86ccddbd5b-9hjhw:\n  Any_Failure: Failure\n\nopentelemetry-demo-ffspostgres-7464b97d47-qz9zg:\n  Any_Failure: Failure\n\nopentelemetry-demo-redis-68779558bb-gmw7r:\n  Any_Failure: Failure\n\nopentelemetry-demo-adservice-59f9578b7c-dfkjg:\n  Any_Failure: Failure\n\nopentelemetry-demo-frauddetectionservice-64cb68b994-4smd7:\n  Any_Failure: Failure\n\nopentelemetry-demo-kafka-bf49b64c9-nmsmn:\n  Any_Failure: Failure\nSaved plot to trends_opentelemetry-demo-currencyservice-77f76b5c58-2xk6g.png\nSaved training history plots\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}